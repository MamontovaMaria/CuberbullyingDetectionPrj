{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bullying recognition from Tweeter Corpus, build on recent events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. First snippet of code reads the file, which containes the tweets in json fromat, gatherered by streiming the tweeter  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd  \n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import difflib\n",
    "import copy\n",
    "from pprint import pprint\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "#Reading the file\n",
    "f = open('pythontest1.json')\n",
    "with open('pythontest1.json',encoding='utf-8') as f:\n",
    "    content = f.readlines()\n",
    "#Getting rid of empty strings\n",
    "content =  [x.strip() for x in content]\n",
    "content = list(filter(None, content)) \n",
    "TweetsJsonArray = []\n",
    "#To JSON TYPE\n",
    "for tweet in content:\n",
    "    TweetsJsonArray.append(json.loads(tweet))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Loading Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "collectivenouns=[]\n",
    "pronouns=[]\n",
    "offensiveWords = dict() \n",
    "xl = pd.ExcelFile(\"Dictionary.xlsx\")\n",
    "\n",
    "df = xl.parse(\"OffensiveWords\")\n",
    "l = len(df)\n",
    "for i in range(l)[1:]:\n",
    "    offensiveWords[(df['Word'][i]).lower()]=df['Weight'][i]\n",
    "    \n",
    "df = xl.parse(\"Nouns\")\n",
    "l = len(df)\n",
    "for i in range(l)[1:]:\n",
    "    collectivenouns.append((df['Collective Nouns'][i]).lower()) \n",
    "    \n",
    "df = xl.parse(\"Pronouns\")\n",
    "l = len(df)\n",
    "for i in range(l)[1:]:\n",
    "    pronouns.append(df['Personal Pronouns'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# reading the bad words file \n",
    "with open('bad-words.csv') as csvfile:    \n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    badwords = []\n",
    "    weight = []\n",
    "    count = []\n",
    "    result = []\n",
    "    for row in readCSV:       \n",
    "        badwords.append(row[0])\n",
    "        weight.append(int(row[1]))\n",
    "#Reading \"Bad words\" from the file\n",
    "with open('nouns.csv', newline='') as csvfile:\n",
    "    readCSV1 = csv.reader(csvfile, delimiter=',')\n",
    "    nouns=[]\n",
    "    for row in readCSV1:\n",
    "        nouns.append(row[0].lower())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The code snippet below contains the functions, used accross the project, such as the Offensiveness level calculation, two tweets similarity calculation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Preprocessing - deleting the similar tweets- deciede that it is not needed\n",
    "import difflib\n",
    "def similar(a, b):\n",
    "    return difflib.SequenceMatcher(None, a, b).ratio()\n",
    "#Calculating the offinsiveness level\n",
    "\n",
    "def offensiveness_weight(TweetText):        \n",
    "        templist = TweetText.split()\n",
    "        offensiveWordsList=list(offensiveWords.keys())\n",
    "        temp = set(offensiveWordsList).intersection(templist)\n",
    "        my_list = list(temp)        \n",
    "        final = 0\n",
    "        result=0\n",
    "        \n",
    "        if len(my_list)!=0:\n",
    "            for word in my_list:                \n",
    "                final = float(final) + float(offensiveWords[word])        \n",
    "            result = final / len(my_list)\n",
    "        return result\n",
    "    \n",
    "#Identifying the existance of the words\n",
    "\n",
    "def wordpresence(TweetText,wordlist):\n",
    "    templist1= TweetText.split()    \n",
    "    temp1 = set(wordlist).intersection(templist1) \n",
    "    my_list1 = list(temp1)    \n",
    "    if len(my_list1)!=0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "# If \n",
    "def offensive_level(TweetText):\n",
    "    \n",
    "    nounsExistance = wordpresence(TweetText,collectivenouns)    \n",
    "    pronounsExistance = wordpresence(TweetText,pronouns)\n",
    "    \n",
    "    if offensiveness_weight(TweetText) > 0 and (wordpresence or pronounsExistance) :    \n",
    "        return (offensiveness_weight(TweetText) + 1)/6 * 100\n",
    "    else:\n",
    "        return (offensiveness_weight(TweetText))/6 * 100\n",
    "#Count how many words from the wordlist parameter are in tweet\n",
    "def WordCount(TweetText,wordlist):\n",
    "    templist1= TweetText.split()    \n",
    "    temp1 = set(wordlist).intersection(templist1) \n",
    "    my_list1 = list(temp1)     \n",
    "    return len(my_list1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Third Party Libriries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "def SentimentalAnalysis(tweet):\n",
    "    r = requests.post(\"http://text-processing.com/api/sentiment/\", data={'text': tweet})\n",
    "    label= r.json()['label']\n",
    "    if label =='neutral':\n",
    "        return 0\n",
    "    elif label=='positive':\n",
    "        return 1\n",
    "    else :        \n",
    "        return 2          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Writing the content to the exel for Manual Analysis\n",
    "import re\n",
    "import csv\n",
    "import json\n",
    "import xlwt\n",
    "import re\n",
    "\n",
    "num=1;\n",
    "book = xlwt.Workbook()\n",
    "sheet1 = book.add_sheet(\"Sheet1\",cell_overwrite_ok=True)\n",
    "\n",
    "row = sheet1.row(0)\n",
    "\n",
    "#row.write(0, 'Created at')\n",
    "row.write(1, 'Text')  \n",
    "row.write(2, 'Names') \n",
    "row.write(3, 'Description') \n",
    "row.write(4, 'Locations') \n",
    "row.write(5, 'Id') \n",
    "row.write(6, 'Offensiveness Weight')\n",
    "row.write(7, 'Offensiveness Level')\n",
    "row.write(8, 'Offensive Words Amount')\n",
    "#row.write(9, 'Collective Nouns Amount')\n",
    "#row.write(10,'Personal Pronouns Amount')\n",
    "row.write(9,'Sentimental Analysis')\n",
    "row.write(10,'Class')\n",
    "\n",
    "n=0\n",
    "for tweet in TweetsJsonArray: \n",
    "    n=n+1\n",
    "    if tweet['lang']==\"en\":\n",
    "        row = sheet1.row(num)\n",
    "        row.write(0, tweet['created_at'])  \n",
    "        text=''\n",
    "        if 'extended_tweet' in tweet:\n",
    "            text=tweet['extended_tweet']['full_text']\n",
    "        elif 'retweeted_status' in tweet:\n",
    "            if 'extended_tweet' in tweet['retweeted_status']:\n",
    "                text=tweet['retweeted_status']['extended_tweet']['full_text']\n",
    "            else:\n",
    "                text=tweet['retweeted_status']['text']\n",
    "        else:\n",
    "            text=tweet['text']\n",
    "        text = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+','',text)\n",
    "        names = tweet['user']['name']\n",
    "        description = tweet['user']['description']\n",
    "        #text = re.sub(r'\\W+', '', text)\n",
    "        \n",
    "        PERMITTED_CHARS = \"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ_- \"\n",
    "        text = \"\".join(c for c in text if c in PERMITTED_CHARS)\n",
    "        text=text.lower()\n",
    "        text=text.strip()\n",
    "        names=\"\".join(c for c in names if c in PERMITTED_CHARS)\n",
    "        description=\"\".join(c for c in description if c in PERMITTED_CHARS) if description!= None else ''\n",
    "        #text=text+\";\\n\"+description       \n",
    "        num=num+1              \n",
    "        \n",
    "        row.write(1, text)\n",
    "        row.write(2, names)\n",
    "        row.write(3, description)\n",
    "        row.write(4, tweet['user']['location'] if tweet['user']['location'] != None else '')\n",
    "        row.write(5, num)      \n",
    "        num=num+1\n",
    "        \n",
    "book.save(\"TweetCorpusExel3.xls\")\n",
    "    #csvFile.writerow([tweet[\"created_at\"],tweet[\"text\"],tweet[\"user\"][\"name\"],tweet[\"user\"][\"description\"],tweet[\"user\"][\"location\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Sort the tweets in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xl = pd.ExcelFile(\"TweetCorpusExel3.xls\")\n",
    "df = xl.parse(\"Sheet1\")\n",
    "df = df.sort_values(by=\"Text\")\n",
    "writer = pd.ExcelWriter('TweetCorpusExel4.xlsx')\n",
    "df.to_excel(writer,'Sheet1',index=False)\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Delete repeating tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/root/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:141: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('TweetCorpusExel4.xlsx', sheetname='Sheet1')\n",
    "writer = pd.ExcelWriter('TweetCorpusExel5.xlsx')\n",
    "currentrow=0\n",
    "if str(df['Description'][currentrow])!='nan':\n",
    "    df['Text'][currentrow]=str(df['Text'][currentrow])+\" \\n <::> \"+str(df['Description'][currentrow])\n",
    "tweet=str(df['Text'][currentrow])\n",
    "\n",
    "l = len(df)\n",
    "\n",
    "for i in range(l)[1:]:   \n",
    "    if df['Text'][i]==tweet or similar(df['Text'][i],tweet)>0.8:        \n",
    "        if len(df['Text'][i])>len(tweet):\n",
    "            df['Text'][currentrow]=df['Text'][i]             \n",
    "        df['Text'][i]=''        \n",
    "        df['Id'][currentrow]=str(df['Id'][currentrow])+\",\"+str(df['Id'][i])\n",
    "        if df['Names'][i]!='':\n",
    "            df['Names'][currentrow]=str(df['Names'][currentrow]) +\",\"+str(df['Names'][i]) \n",
    "        if str(df['Locations'][i])!='nan':\n",
    "            df['Locations'][currentrow]=str(df['Locations'][currentrow])+\",\"+str(df['Locations'][i])\n",
    "        \n",
    "        if str(df['Description'][i])!='nan':\n",
    "               df['Text'][currentrow]=str(df['Text'][currentrow])+\" \\n <::> \"+str(df['Description'][i])\n",
    "    else:\n",
    "        tweet=str(df['Text'][currentrow])\n",
    "        df['Offensiveness Weight'][currentrow]=offensiveness_weight(tweet)        \n",
    "        df['Offensiveness Level'][currentrow]=offensive_level(tweet) \n",
    "        df['Offensive Words Amount'][currentrow]=WordCount(tweet,offensiveWords)\n",
    "        df['Sentimental Analysis'][currentrow]=SentimentalAnalysis(tweet)\n",
    "        currentrow=i        \n",
    "        tweet=str(df['Text'][currentrow])               \n",
    "                      \n",
    "df = df[df.Text != '']   \n",
    "df.to_excel(writer,'Sheet1',index=False)\n",
    "writer.save()\n",
    "writer.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('TweetCorpusExel5.xlsx', sheetname='Sheet1')\n",
    "writer = pd.ExcelWriter('TweetCorpusExelML.xlsx')\n",
    "del df['Description']\n",
    "\n",
    "del df['Names']\n",
    "del df['Locations']\n",
    "del df['Id']\n",
    "df.to_excel(writer,'Sheet1',index=False)\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('TweetCorpusExelML.xlsx', sheetname='Sheet1') \n",
    "writer = pd.ExcelWriter('processed.xlsx')\n",
    "#df['O_Weight']=df['O_Weight'].fillna(999)\n",
    "#df['O_level']=df['O_level'].fillna(999)\n",
    "df=df.dropna() # drops rows with Nan\n",
    "#cols = ['Offensiveness Level', 'Offensive Words Amount','Offensiveness Weight','Sentimental Analysis', 'Class']\n",
    "#df[cols] = df[cols].applymap(np.int64)\n",
    "\n",
    "del df['Text']\n",
    "\n",
    "df.to_excel(writer,'Sheet1',index=False)\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "dataset = pd.read_excel(open('processed.xlsx','rb'), sheetname='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Offensiveness Weight  Offensiveness Level  Offensive Words Amount  \\\n",
      "0                    0.0             0.000000                       0   \n",
      "1                    1.5            41.666667                       2   \n",
      "2                    1.0            33.333333                       1   \n",
      "3                    0.0             0.000000                       0   \n",
      "4                    1.0            33.333333                       1   \n",
      "5                    0.0             0.000000                       0   \n",
      "6                    0.0             0.000000                       0   \n",
      "7                    0.0             0.000000                       0   \n",
      "8                    0.0             0.000000                       0   \n",
      "9                    0.0             0.000000                       0   \n",
      "10                   0.0             0.000000                       0   \n",
      "11                   2.5            58.333333                       2   \n",
      "12                   3.0            66.666667                       2   \n",
      "13                   0.0             0.000000                       0   \n",
      "14                   1.0            33.333333                       1   \n",
      "15                   0.0             0.000000                       0   \n",
      "16                   0.0             0.000000                       0   \n",
      "17                   1.0            33.333333                       1   \n",
      "18                   1.0            33.333333                       2   \n",
      "19                   1.0            33.333333                       1   \n",
      "\n",
      "    Sentimental Analysis  Class  \n",
      "0                      2      0  \n",
      "1                      0      1  \n",
      "2                      0      1  \n",
      "3                      0      0  \n",
      "4                      0      1  \n",
      "5                      0      0  \n",
      "6                      0      0  \n",
      "7                      2      0  \n",
      "8                      0      0  \n",
      "9                      0      0  \n",
      "10                     0      0  \n",
      "11                     0      1  \n",
      "12                     0      1  \n",
      "13                     2      0  \n",
      "14                     0      1  \n",
      "15                     2      1  \n",
      "16                     2      0  \n",
      "17                     0      0  \n",
      "18                     0      1  \n",
      "19                     0      0  \n"
     ]
    }
   ],
   "source": [
    "print(dataset.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(332, 5)\n",
      "       Offensiveness Weight  Offensiveness Level  Offensive Words Amount  \\\n",
      "count            332.000000           332.000000              332.000000   \n",
      "mean               0.966616            23.138387                0.578313   \n",
      "std                1.408890            30.509416                0.813340   \n",
      "min                0.000000             0.000000                0.000000   \n",
      "25%                0.000000             0.000000                0.000000   \n",
      "50%                0.000000             0.000000                0.000000   \n",
      "75%                2.000000            50.000000                1.000000   \n",
      "max                5.000000           100.000000                5.000000   \n",
      "\n",
      "       Sentimental Analysis       Class  \n",
      "count            332.000000  332.000000  \n",
      "mean               0.518072    0.460843  \n",
      "std                0.877534    0.499217  \n",
      "min                0.000000    0.000000  \n",
      "25%                0.000000    0.000000  \n",
      "50%                0.000000    0.000000  \n",
      "75%                2.000000    1.000000  \n",
      "max                2.000000    1.000000  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'class'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2133\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2134\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2135\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4433)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4279)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13742)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13696)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'class'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-49ab05cc2aa3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, **kwargs)\u001b[0m\n\u001b[1;32m   3989\u001b[0m         return groupby(self, by=by, axis=axis, level=level, as_index=as_index,\n\u001b[1;32m   3990\u001b[0m                        \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3991\u001b[0;31m                        **kwargs)\n\u001b[0m\u001b[1;32m   3992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3993\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0masfreq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/pandas/core/groupby.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(obj, by, **kwds)\u001b[0m\n\u001b[1;32m   1509\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'invalid type: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/pandas/core/groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m                                                     \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m                                                     \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m                                                     mutated=self.mutated)\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/pandas/core/groupby.py\u001b[0m in \u001b[0;36m_get_grouper\u001b[0;34m(obj, key, axis, level, sort, mutated)\u001b[0m\n\u001b[1;32m   2460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2461\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_in_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# df.groupby('name')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2462\u001b[0;31m             \u001b[0min_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2463\u001b[0m             \u001b[0mexclusions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2464\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2057\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2064\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2066\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2068\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1384\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1386\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1387\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3542\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3543\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3544\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3545\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2134\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2136\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4433)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4279)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13742)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13696)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'class'"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)\n",
    "print(dataset.describe())\n",
    "print(dataset.groupby('class').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "array = dataset.values\n",
    "X = array[:,0:4]\n",
    "Y = array[:,4]\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test options and evaluation metric\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.799858 (0.054046)\n",
      "LDA: 0.799858 (0.054046)\n",
      "KNN: 0.776781 (0.104415)\n",
      "CART: 0.792308 (0.048849)\n",
      "NB: 0.784758 (0.066335)\n",
      "SVM: 0.799858 (0.054046)\n"
     ]
    }
   ],
   "source": [
    "# Spot Check Algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (wordpresence('sweden is the worlds best country for immigrant us studysurprising'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "similar('ad','ads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def EmotionsAnalysis(tweet):\n",
    "    \n",
    "    headers={\n",
    "    \"X-Mashape-Key\": \"9zdoXpyV3Jmshr0ehYsqOnCT6i3np1F4iMqjsnq4mEJLTej82W\",\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Content-Type\": \"application/x-www-form-urlencoded\"\n",
    "    }\n",
    "    params={\n",
    "    \"lang\": \"en\",\n",
    "    \"text\": \"a lot of us wont debate with liberalspro-islamlgbtanti-christians but just because were quiet dont misunderstand our intentions\"}\n",
    "    r = requests.post(\"https://shl-mp.p.mashape.com/webresources/jammin/emotionV2\",headers=headers,params=params)\n",
    "    jsonObject= r.json()\n",
    "    return jsonObject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jsonObject=EmotionsAnalysis('a lot of us wont debate with liberalspro-islamlgbtanti-christians but just because were quiet dont misunderstand our intentions')\n",
    "print(jsonObject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Updating classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('TweetCorpusExelMLV.xlsx', sheetname='Sheet1')\n",
    "df2 = pd.read_excel('TweetCorpusExel6.xlsx', sheetname='Sheet1')\n",
    "\n",
    "l = len(df)\n",
    "for i in range(l)[1:]: \n",
    "    tweet=df['Class'][i]\n",
    "    df2[df2['A'].str.contains(\"tweet\")==True]\n",
    "\n",
    "    \n",
    "writer.save()\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
